{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN classifier for the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "The goal of this project is to build and train a Convolutional Neural Network (CNN) to classify handwritten digits from the famous MNIST dataset. \n",
    "\n",
    "Using **TensorFlow** and **Keras**, we will:\n",
    "1. Load and preprocess the image data.\n",
    "2. Design a CNN architecture suitable for image classification.\n",
    "3. Train the model and visualize the learning performance (Accuracy/Loss).\n",
    "4. Evaluate the model on unseen test data.\n",
    "\n",
    "**Stack:** Python, TensorFlow 2, Pandas, Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing\n",
    "\n",
    "The MNIST dataset contains 60,000 training images and 10,000 testing images of normalized handwritten digits.\n",
    "We normalize the pixel values to be between 0 and 1 to improve training convergence and add a channel dimension to match the expected CNN input format (Height, Width, Channel)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "def load_and_process_data():\n",
    "    \"\"\"\n",
    "    Loads the MNIST dataset and performs necessary preprocessing steps for CNN training.\n",
    "    \n",
    "    Steps:\n",
    "    1. Load raw data (split into train/test).\n",
    "    2. Normalize pixel intensity values to range [0, 1].\n",
    "    3. Reshape input tensors to include the channel dimension (Grayscale).\n",
    "    \n",
    "    Returns:\n",
    "        tuple: ((train_images, train_labels), (test_images, test_labels))\n",
    "    \"\"\"\n",
    "    # Load data from TensorFlow/Keras datasets\n",
    "    mnist_data = tf.keras.datasets.mnist\n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist_data.load_data()\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # NORMALIZATION\n",
    "    # ---------------------------------------------------------\n",
    "    # Neural networks converge faster and more strictly when inputs are small.\n",
    "    # We scale the pixel values from [0, 255] to [0.0, 1.0].\n",
    "    train_images = train_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # RESHAPING FOR CNN\n",
    "    # ---------------------------------------------------------\n",
    "    # Keras Conv2D layers expect a 4D tensor input: (Batch_Size, Height, Width, Channels).\n",
    "    # Since MNIST is grayscale, we add a single channel dimension at the end.\n",
    "    # Shape transformation: (60000, 28, 28) -> (60000, 28, 28, 1)\n",
    "    train_images = train_images[..., np.newaxis]\n",
    "    test_images = test_images[..., np.newaxis]\n",
    "    \n",
    "    return (train_images, train_labels), (test_images, test_labels)\n",
    "\n",
    "# Execute loading\n",
    "(scaled_train_images, train_labels), (scaled_test_images, test_labels) = load_and_process_data()\n",
    "\n",
    "print(f\"Training set tensor shape: {scaled_train_images.shape}\")\n",
    "print(f\"Test set tensor shape: {scaled_test_images.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Neural Network Architecture\n",
    "\n",
    "We construct a Sequential CNN model with the following layers:\n",
    "* **Conv2D**: 8 filters, 3x3 kernel, ReLU activation, 'SAME' padding.\n",
    "* **MaxPooling2D**: Downsampling with a 2x2 window.\n",
    "* **Flatten**: Converts 2D feature maps to 1D vectors.\n",
    "* **Dense**: Two fully connected layers with 64 units each (ReLU).\n",
    "* **Output**: Softmax layer with 10 units (representing digits 0-9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(input_shape):\n",
    "    \"\"\"\n",
    "    Constructs a Sequential Convolutional Neural Network (CNN).\n",
    "    \n",
    "    Architecture Design:\n",
    "    - Feature Extraction Block: Conv2D + MaxPooling\n",
    "    - Classifier Block: Flatten + Dense layers\n",
    "    \n",
    "    Args:\n",
    "        input_shape (tuple): The shape of a single input image (H, W, C).\n",
    "        \n",
    "    Returns:\n",
    "        tf.keras.Model: The uncompiled Keras model.\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        # =================================================================\n",
    "        # FEATURE EXTRACTION LAYERS\n",
    "        # =================================================================\n",
    "        # Conv2D: Learns spatial filters (edges, textures) from the input image.\n",
    "        # - filters=8: We learn 8 different feature maps.\n",
    "        # - kernel_size=(3,3): Standard size for local feature detection.\n",
    "        # - padding='SAME': Output spatial dimensions match input dimensions.\n",
    "        tf.keras.layers.Conv2D(8, (3, 3), padding='SAME', activation='relu', input_shape=input_shape),\n",
    "        \n",
    "        # MaxPooling2D: Downsamples the input representation.\n",
    "        # This reduces computational cost and helps make the model robust to small translations.\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        # =================================================================\n",
    "        # CLASSIFICATION LAYERS\n",
    "        # =================================================================\n",
    "        # Flatten: Unrolls the 3D output of the convolutional part into a 1D vector.\n",
    "        tf.keras.layers.Flatten(),\n",
    "\n",
    "        # Dense (Hidden): Fully connected layers to interpret the features.\n",
    "        # ReLU activation introduces non-linearity, allowing the model to learn complex patterns.\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "\n",
    "        # Output Layer: 10 neurons correspond to the 10 digit classes (0-9).\n",
    "        # Softmax activation converts raw scores (logits) into probabilities summing to 1.\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Instantiate and visualize the model architecture\n",
    "model = build_cnn_model(scaled_train_images[0].shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# COMPILATION\n",
    "# ---------------------------------------------------------\n",
    "# Optimizer: 'Adam' is an adaptive learning rate optimization algorithm \n",
    "# that is generally efficient for computer vision tasks.\n",
    "# Loss Function: 'sparse_categorical_crossentropy' is used because:\n",
    "#   1. It is a multi-class classification problem.\n",
    "#   2. Our targets (labels) are integers (e.g., 5), not one-hot vectors.\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# TRAINING\n",
    "# ---------------------------------------------------------\n",
    "# We fit the model to the training data.\n",
    "# Epochs: Number of full passes through the dataset.\n",
    "print(\"Starting training process...\")\n",
    "history = model.fit(\n",
    "    scaled_train_images, \n",
    "    train_labels, \n",
    "    epochs=5, \n",
    "    verbose=1  # Displays a progress bar\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Performance\n",
    "\n",
    "Visualizing the accuracy and loss over the training epochs helps identify if the model is learning correctly or overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# LEARNING CURVES VISUALIZATION\n",
    "# ---------------------------------------------------------\n",
    "# We use Pandas to easily manage the history dictionary returned by Keras.\n",
    "# The history object contains the loss and metric values for each epoch.\n",
    "frame = pd.DataFrame(history.history)\n",
    "\n",
    "# Initialize a figure with two subplots side-by-side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ACCURACY PLOT\n",
    "# ---------------------------------------------------------\n",
    "# A rising curve indicates the model is correctly learning to classify the training data.\n",
    "axes[0].plot(frame['accuracy'], label='Train Accuracy')\n",
    "axes[0].set_title('Accuracy vs Epochs')\n",
    "axes[0].set_xlabel('Epochs')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].grid(True) # Adding grid for better readability\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# LOSS PLOT\n",
    "# ---------------------------------------------------------\n",
    "# The loss (error) should decrease over time. \n",
    "# A flat line would indicate the model has stopped learning (convergence or stuck in local minima).\n",
    "axes[1].plot(frame['loss'], color='orange', label='Train Loss')\n",
    "axes[1].set_title('Loss vs Epochs')\n",
    "axes[1].set_xlabel('Epochs')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout() # Adjusts subplot params so that subplots are nicely fit in the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation & Predictions\n",
    "\n",
    "Finally, we assess the model's performance on the unseen test set and visualize specific predictions along with their confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# EVALUATION ON TEST SET\n",
    "# ---------------------------------------------------------\n",
    "# We assess the model on data it has never seen before to check for overfitting.\n",
    "test_loss, test_accuracy = model.evaluate(scaled_test_images, test_labels, verbose=0)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Final Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Final Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# PREDICTION VISUALIZATION\n",
    "# ---------------------------------------------------------\n",
    "# Visualize model confidence on a few random samples\n",
    "\n",
    "# Randomly select 4 images from the test set\n",
    "num_test_images = scaled_test_images.shape[0]\n",
    "random_inx = np.random.choice(num_test_images, 4)\n",
    "random_test_images = scaled_test_images[random_inx, ...]\n",
    "random_test_labels = test_labels[random_inx, ...]\n",
    "\n",
    "# Get probability distributions\n",
    "predictions = model.predict(random_test_images)\n",
    "\n",
    "fig, axes = plt.subplots(4, 2, figsize=(16, 12))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=-0.2)\n",
    "\n",
    "for i, (prediction, image, label) in enumerate(zip(predictions, random_test_images, random_test_labels)):\n",
    "    # Plot the image\n",
    "    axes[i, 0].imshow(np.squeeze(image), cmap='gray') # Remove channel dim for plotting\n",
    "    axes[i, 0].axis('off')\n",
    "    axes[i, 0].text(10., -1.5, f'True Label: {label}', fontsize=12, color='blue')\n",
    "    \n",
    "    # Plot the confidence bar chart\n",
    "    axes[i, 1].bar(np.arange(len(prediction)), prediction, color='gray')\n",
    "    axes[i, 1].set_xticks(np.arange(len(prediction)))\n",
    "    \n",
    "    # Highlight the predicted class\n",
    "    pred_label = np.argmax(prediction)\n",
    "    confidence = np.max(prediction)\n",
    "    \n",
    "    title = f\"Prediction: {pred_label} ({confidence:.1%})\"\n",
    "    axes[i, 1].set_title(title, fontsize=12, fontweight='bold')\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
